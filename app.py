import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
except ImportError:
    # å¿…è¦ã«å¿œã˜ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    import os
    os.system('pip install -q transformers torch fugashi ipadic unidic-lite')
    from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿæƒ…åˆ†æ",
    page_icon="ğŸ­",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¤ãƒ³ãƒˆãƒ­
st.title("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒª")
st.write("ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«æ–‡ç« ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€AIãŒæ„Ÿæƒ…ã‚’åˆ†æã—ã¦ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã—ã¾ã™ï¼")

# æ„Ÿæƒ…ã®ãƒªã‚¹ãƒˆ
emotion_names_jp = ['å–œã³', 'æ‚²ã—ã¿', 'æœŸå¾…', 'é©šã', 'æ€’ã‚Š', 'æã‚Œ', 'å«Œæ‚ª', 'ä¿¡é ¼']
colors = [
    '#FF6384',  # èµ¤ (å–œã³)
    '#36A2EB',  # é’ (æ‚²ã—ã¿)
    '#FFCE56',  # é»„ (æœŸå¾…)
    '#4BC0C0',  # ç·‘ (é©šã)
    '#9966FF',  # ç´« (æ€’ã‚Š)
    '#FF9F40',  # ã‚ªãƒ¬ãƒ³ã‚¸ (æã‚Œ)
    '#C7C7C7',  # ã‚°ãƒ¬ãƒ¼ (å«Œæ‚ª)
    '#53E1A2'   # ãƒŸãƒ³ãƒˆ (ä¿¡é ¼)
]

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if 'model' not in st.session_state or 'tokenizer' not in st.session_state:
    # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
    with st.spinner('ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™'):
        try:
            # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
            import os
            os.environ['HF_DATASETS_OFFLINE'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '1'
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
            cache_dir = "./model_cache"
            
            try:
                # ã¾ãšè»½é‡ãƒ¢ãƒ‡ãƒ«ã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã®èª­ã¿è¾¼ã¿ã‚’è©¦ã™
                checkpoint = 'cl-tohoku/bert-base-japanese-v2'
                st.session_state.tokenizer = AutoTokenizer.from_pretrained(
                    checkpoint, cache_dir=cache_dir, local_files_only=True)
                st.session_state.model = AutoModelForSequenceClassification.from_pretrained(
                    checkpoint, num_labels=len(emotion_names_jp), cache_dir=cache_dir, local_files_only=True)
                st.success('ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼')
            except:
                # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹ã«ã—ã¦å†è©¦è¡Œ
                os.environ['HF_DATASETS_OFFLINE'] = '0'
                os.environ['TRANSFORMERS_OFFLINE'] = '0'
                
                checkpoint = 'cl-tohoku/bert-base-japanese-v2'
                st.session_state.tokenizer = AutoTokenizer.from_pretrained(
                    checkpoint, cache_dir=cache_dir)
                st.session_state.model = AutoModelForSequenceClassification.from_pretrained(
                    checkpoint, num_labels=len(emotion_names_jp), cache_dir=cache_dir)
                st.success('ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
        
        except Exception as e:
            st.error(f'ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}')
            st.warning('ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãªæ„Ÿæƒ…å€¤ã‚’ä½¿ç”¨ï¼‰')
            
            # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’è¨­å®š
            import random
            
            class DummyModel:
                def eval(self):
                    pass
                
                def __call__(self, **kwargs):
                    class DummyOutput:
                        def __init__(self):
                            self.logits = np.random.rand(1, len(emotion_names_jp))
                    return DummyOutput()
            
            class DummyTokenizer:
                def __call__(self, text, truncation=True, return_tensors="pt"):
                    return {}
            
            st.session_state.model = DummyModel()
            st.session_state.tokenizer = DummyTokenizer()

# Softmaxé–¢æ•°
def np_softmax(x):
    f_x = np.exp(x) / np.sum(np.exp(x))
    return f_x

# æ„Ÿæƒ…åˆ†æé–¢æ•°
def analyze_emotion(text):
    try:
        # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
        st.session_state.model.eval()

        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å¤‰æ› + æ¨è«–
        tokens = st.session_state.tokenizer(text, truncation=True, return_tensors="pt")
        preds = st.session_state.model(**tokens)
        prob = np_softmax(preds.logits.cpu().detach().numpy()[0])
        return {n: float(p) for n, p in zip(emotion_names_jp, prob)}
    except Exception as e:
        st.warning(f"æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªå€¤ã‚’è¿”ã™
        import random
        random_values = [random.random() for _ in range(len(emotion_names_jp))]
        total = sum(random_values)
        normalized = [v/total for v in random_values]
        return {n: float(p) for n, p in zip(emotion_names_jp, normalized)}

# ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢
text_input = st.text_area("ã“ã“ã«åˆ†æã—ãŸã„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", height=150)

# ãƒ‡ãƒ¢ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
st.markdown("### ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ")
sample_texts = [
    "ä»Šæ—¥ã¯ã¨ã¦ã‚‚æ¥½ã—ã„ä¸€æ—¥ã§ã—ãŸï¼",
    "æ‚²ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èã„ã¦ã‚·ãƒ§ãƒƒã‚¯ã‚’å—ã‘ã¦ã„ã¾ã™ã€‚",
    "æ˜æ—¥ã®æ—…è¡ŒãŒã¨ã¦ã‚‚æ¥½ã—ã¿ã§ã™ï¼",
    "çªç„¶ã®çŸ¥ã‚‰ã›ã«é©šã„ã¦ã„ã¾ã™ã€‚",
    "ã“ã®å¯¾å¿œã«ã¯æœ¬å½“ã«è…¹ãŒç«‹ã¡ã¾ã™ã€‚"
]

# ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆãƒœã‚¿ãƒ³
cols = st.columns(len(sample_texts))
for i, col in enumerate(cols):
    if col.button(f"ã‚µãƒ³ãƒ—ãƒ«{i+1}"):
        text_input = sample_texts[i]
        st.session_state.text_input = sample_texts[i]
        st.experimental_rerun()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å‡¦ç†
if 'text_input' in st.session_state:
    text_input = st.session_state.text_input

# åˆ†æãƒœã‚¿ãƒ³
if st.button('åˆ†æã™ã‚‹') or text_input:
    if text_input:
        with st.spinner('æ„Ÿæƒ…ã‚’åˆ†æä¸­...'):
            # å®Ÿéš›ã®åˆ†æå‡¦ç†
            result = analyze_emotion(text_input)
            
            # çµæœã®è¡¨ç¤º
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                fig, ax = plt.subplots(figsize=(10, 6))
                emotions = list(result.keys())
                values = list(result.values())
                
                # æœ€å¤§å€¤ã®ä½ç½®ã‚’å–å¾—
                max_index = values.index(max(values))
                
                # è‰²ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆæœ€å¤§å€¤ã®å ´æ‰€ã‚’å¼·èª¿ï¼‰
                bar_colors = [colors[i] + '99' for i in range(len(emotions))]
                bar_colors[max_index] = colors[max_index]
                
                # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ãƒ—ãƒ­ãƒƒãƒˆ
                bars = ax.bar(emotions, values, color=bar_colors)
                
                # ã‚°ãƒ©ãƒ•ã®è¨­å®š
                ax.set_ylim(0, 1)
                ax.set_ylabel('ç¢ºç‡')
                ax.set_title('æ„Ÿæƒ…åˆ†æçµæœ')
                
                # æœ€å¤§å€¤ã®ãƒãƒ¼ã«ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
                ax.text(max_index, values[max_index] + 0.02, f'{values[max_index]:.3f}', 
                        ha='center', va='bottom', fontsize=12, weight='bold')
                
                st.pyplot(fig)
            
            with col2:
                # çµæœã®è¡¨ç¤º
                st.write("### æ„Ÿæƒ…ã‚¹ã‚³ã‚¢")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                df = pd.DataFrame({
                    'æ„Ÿæƒ…': emotions,
                    'ç¢ºç‡': [round(v, 3) for v in values]
                })
                
                # ç¢ºç‡ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
                df = df.sort_values('ç¢ºç‡', ascending=False).reset_index(drop=True)
                
                # è¡¨å½¢å¼ã§è¡¨ç¤º
                st.dataframe(df, height=300)
                
                # æœ€ã‚‚å¼·ã„æ„Ÿæƒ…ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
                max_emotion = df.iloc[0]['æ„Ÿæƒ…']
                max_prob = df.iloc[0]['ç¢ºç‡']
                st.markdown(f"### æœ€ã‚‚å¼·ã„æ„Ÿæƒ…: **{max_emotion}** ({max_prob:.3f})")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("### ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã¯æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æã—ã€8ã¤ã®åŸºæœ¬æ„Ÿæƒ…ï¼ˆå–œã³ã€æ‚²ã—ã¿ã€æœŸå¾…ã€é©šãã€æ€’ã‚Šã€æã‚Œã€å«Œæ‚ªã€ä¿¡é ¼ï¼‰ã®ç¢ºç‡ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
st.write("åˆ†æã«ã¯æ±åŒ—å¤§å­¦ã®æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚")
